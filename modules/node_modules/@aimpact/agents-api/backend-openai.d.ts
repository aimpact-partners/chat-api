/************
Processor: ts
************/

import * as __beyond_dep_ns_0 from 'fs';
import __beyond_dep_def_1 from 'openai';
// buckets\read.ts
declare namespace ns_0 {
  /// <reference types="node" />
  import fs = __beyond_dep_ns_0;
  export function getFile(fileName: string): Promise<fs.ReadStream>;
}


// index.ts
declare namespace ns_1 {
  /// <reference types="node" />
  import OpenAI = __beyond_dep_def_1;
  export class OpenAIBackend {
    #private;
    completions(prompt: string, text: string): Promise<{
      status: boolean;
      data: string;
      error?: undefined;
    } | {
      status: boolean;
      error: any;
      data?: undefined;
    }>;
    chatCompletions(messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[], model?: string, temperature?: number): Promise<{
      status: boolean;
      data: string;
      error?: undefined;
    } | {
      status: boolean;
      error: any;
      data?: undefined;
    }>;
    /**
     *
     * @param path
     * @param lang
     * @returns
     */
    transcription(file: any, lang?: string): Promise<any>;
    transcriptionStream(stream: NodeJS.ReadableStream, lang: string): Promise<{
      status: boolean;
      data?: any;
      error?: string;
      code?: number;
    }>;
  }
}


// utils\models.ts
declare namespace ns_2 {
  export const whisper = "whisper-1";
  export const gpt4 = "gpt-4-0314";
  export const gptTurbo = "gpt-3.5-turbo";
  export const gptTurboPlus = "gpt-3.5-turbo-0613";
  export const ada = "text-ada-001";
  export const currie1 = "text-curie-001";
  export const babbage = "text-babbage-001";
  export const davinci2 = "text-davinci-002";
  export const davinci3 = "text-davinci-003";
}


export import OpenAIBackend = ns_1.OpenAIBackend;

export declare const hmr: {on: (event: string, listener: any) => void, off: (event: string, listener: any) => void };